{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import LRScheduler, StepLR\n",
    "\n",
    "from data_loading.dataset import generate_dataloaders\n",
    "from metrics.iou import calculate_iou, CHAOSIoUTracker\n",
    "from metrics.loss import LossTracker, calculate_loss\n",
    "from unet import UNet"
   ],
   "id": "4611d6b3ec84f4e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "2e13d466085162f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 50\n",
    "LR = .001\n",
    "WEIGHT_DECAY = .0001\n",
    "STEP_SIZE = 30"
   ],
   "id": "2347a2c6a1afacde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generating Dataloaders for feeding the NN",
   "id": "7fd81f0f33a8bca6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataloaders = generate_dataloaders(batch_size=BATCH_SIZE, validation_split=0.20)",
   "id": "adc2e15d2eaeceeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Definition",
   "id": "1bb504381d2c47f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = UNet(n_classes=N_CLASSES)",
   "id": "1d52015351514623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Log Functions",
   "id": "6dabcb63b93ad7aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_metric_to_console(name: str, train_metric: dict, valid_metric: dict) -> None:\n",
    "    \"\"\"\n",
    "    Formats and prints training and validation metric values to console.\n",
    "    Expected metric dict:\n",
    "        {\n",
    "        \"metric1\": metric_value1,\n",
    "        \"metric2\": metric_value2,\n",
    "        \"metric3\": metric_value3,\n",
    "        ... }\n",
    "    \"\"\"\n",
    "    print(f\"{name.upper()}:\")\n",
    "    metric_dict = {\"train\": train_metric, \"valid\": valid_metric}\n",
    "    for phase, metric in metric_dict.items():\n",
    "        output = \" \".join(f\"{cls}: {score:.5f}\" for cls, score in metric.items())\n",
    "        print(f\"\\t({phase}) {output}\")\n",
    "\n",
    "\n",
    "def print_metric_to_tb(writer: SummaryWriter, train_metric: dict, valid_metric: dict, epoch: int) -> None:\n",
    "    \"\"\"\n",
    "    Prints training and validation metric values to Tensorboard.\n",
    "    Expected metric dict:\n",
    "        {\n",
    "        \"metric1\": metric_value1,\n",
    "        \"metric2\": metric_value2,\n",
    "        \"metric3\": metric_value3,\n",
    "        ... }\n",
    "    \"\"\"\n",
    "    for cls in train_metric.keys():\n",
    "        scalar_dict = {\n",
    "            \"train\": train_metric[cls],\n",
    "            \"valid\": valid_metric[cls]\n",
    "        }\n",
    "        writer.add_scalars(main_tag=cls, tag_scalar_dict=scalar_dict, global_step=epoch)\n",
    "\n",
    "\n",
    "WRITER_LOSS = SummaryWriter(\"logs/loss\")\n",
    "WRITER_ACCURACY = SummaryWriter(\"logs/accuracy\")"
   ],
   "id": "9e0ade43f9ee904d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop",
   "id": "ef9729826591240"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_run_name(\n",
    "        model_name: str,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        lr: float,\n",
    "        step_size: int,\n",
    "        weight_decay: float\n",
    ") -> str:\n",
    "    timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return f\"{model_name}_EP{epochs}_BS{batch_size}_LR{lr}_Step{step_size}_WD{weight_decay}_{timestamp}\"\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: Module,\n",
    "        dataloaders: dict,\n",
    "        n_epochs: int,\n",
    "        optimizer: Optimizer,\n",
    "        scheduler: LRScheduler,\n",
    "        device: torch.device = torch.device(\"cpu\")\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{n_epochs}\\n{'=' * 30}\")\n",
    "        print(f\"LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            loss_tracker = LossTracker()\n",
    "            accuracy_tracker = CHAOSIoUTracker()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                for images, masks in dataloaders[phase]:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    prediction = model(images)\n",
    "\n",
    "                    loss = calculate_loss(prediction=prediction, ground_truth=masks)\n",
    "                    loss_tracker.update(losses=loss, batch_size=masks.size(0))\n",
    "\n",
    "                    iou_score = calculate_iou(prediction=prediction, ground_truth=masks)\n",
    "                    accuracy_tracker.update(batch_iou=iou_score, batch_size=masks.size(0))\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss[\"loss\"].backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "            avg_loss = loss_tracker.get_results()\n",
    "            avg_accuracy = accuracy_tracker.get_results()\n",
    "\n",
    "            if phase == \"train\":\n",
    "                train_loss = avg_loss  # save the training loss\n",
    "                train_accuracy = avg_accuracy  # save the training accuracy\n",
    "            else:\n",
    "                # print loss\n",
    "                print_metric_to_console(name=\"LOSS\", train_metric=train_loss, valid_metric=avg_loss)\n",
    "                print_metric_to_tb(writer=WRITER_LOSS, train_metric=train_loss, valid_metric=avg_loss, epoch=epoch)\n",
    "\n",
    "                # print accuracy\n",
    "                print_metric_to_console(\n",
    "                    name=\"ACCURACY(IoU)\",\n",
    "                    train_metric=train_accuracy,\n",
    "                    valid_metric=avg_accuracy\n",
    "                )\n",
    "                print_metric_to_tb(\n",
    "                    writer=WRITER_ACCURACY,\n",
    "                    train_metric=train_accuracy,\n",
    "                    valid_metric=avg_accuracy,\n",
    "                    epoch=epoch\n",
    "                )\n",
    "                if avg_loss[\"loss\"] < best_loss:\n",
    "                    print(\"Saving best model...\")\n",
    "                    best_loss = avg_loss[\"loss\"]\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        finish_time = round(time.time() - start_time)\n",
    "        print(f\"TIME: {finish_time // 60}min {finish_time % 60}s\")\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best validation loss: {best_loss:.5f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    run_name = generate_run_name(model_name=\"UNet\",\n",
    "                                 weight_decay=WEIGHT_DECAY,\n",
    "                                 lr=LR,\n",
    "                                 step_size=STEP_SIZE,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 epochs=N_EPOCHS\n",
    "                                 )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./models/{run_name}.pth\")\n"
   ],
   "id": "55e32fd2653dcbb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/losses"
   ],
   "id": "c72dfdf6b99848a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir logs/accuracies",
   "id": "b77f89fec446c660",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Optimizer, LR Scheduler and Start Training",
   "id": "a5f023d7aff74d0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = StepLR(optimizer=optimizer, step_size=STEP_SIZE, gamma=0.1)\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    device=device\n",
    ")"
   ],
   "id": "86f4144831c7a757",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MODEL EVALUATION\n",
   "id": "d7baf5b46b64147e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np",
   "id": "95247230001fa38f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:37:12.041599Z",
     "start_time": "2025-03-11T20:37:11.506508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"./models/MODEL_NAME\"  # add name of the model\n",
    "model = UNet(n_classes=N_CLASSES)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(model_path, weights_only=True))"
   ],
   "id": "64e75151dcf2cee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def binary_stack_to_rgb_image(mask: np.array) -> np.array:\n",
    "    channels, height, width = mask.shape\n",
    "    colored_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    colors = np.array([\n",
    "        (201, 58, 64),  # Red - Liver\n",
    "        (242, 207, 1),  # Yellow - Right Kidney\n",
    "        (0, 152, 75),  # Green - Left Kidney\n",
    "        (101, 172, 228)  # Blue - Spleen\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "    for class_index in range(channels):\n",
    "        colored_img[mask[class_index]] = colors[class_index]\n",
    "\n",
    "    return colored_img\n"
   ],
   "id": "39ac2312fdde14fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
