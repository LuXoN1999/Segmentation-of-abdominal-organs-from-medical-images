{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from tools.data_loading import get_colormap, read_image, read_mask\n",
    "from unet import UnetBuilder\n",
    "from metrics import dice_coef, dice_loss, iou"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f061b0eeb9d02b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# HYPERPARAMS\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 16  # 15 labels of abdominal organs + background label\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 75\n",
    "\n",
    "DATASET_PATH = \"./data\"\n",
    "MODEL_PATH = os.path.join(\"files\", \"model.h5\")\n",
    "CSV_PATH = os.path.join(\"files\", \"data.csv\")\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "694f2ed3117cc441",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "create_dir(\"files\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45d25471c60931a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_dataset(path, split=0.25, log_feedback=False):\n",
    "    images = sorted(glob(os.path.join(path, \"train\", \"img\", \"*\")))[:5000]  # take 5k images\n",
    "    masks = sorted(glob(os.path.join(path, \"train\", \"msk\", \"*\")))[:5000]  # take 5k masks\n",
    "    split_size = int(split * len(images))\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
    "    if log_feedback:\n",
    "        print(f\"NUMBER OF PAIRS:\\nTraining: {len(train_x)}/{len(train_y)}\\nValidation: {len(valid_x)}/{len(valid_y)}\")\n",
    "    return (train_x, train_y), (valid_x, valid_y)\n",
    "\n",
    "\n",
    "(train_x, train_y), (valid_x, valid_y) = load_dataset(path=DATASET_PATH, log_feedback=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7048e130a09bc3a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CLASSES, COLORMAP = get_colormap(\"./organ_labels.json\")\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y, COLORMAP)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.uint8])\n",
    "    image.set_shape([IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    mask.set_shape([IMG_HEIGHT, IMG_WIDTH, N_CLASSES])\n",
    "    return image, mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "284fd7937fe00a77",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch_size=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.shuffle(buffer_size=5000)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(2)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3bf25a8b71750a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch_size=BATCH_SIZE)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8236425bd12e5eed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = UnetBuilder.build_unet(input_shape=INPUT_SHAPE, n_classes=N_CLASSES)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd51abc1d95e3fb0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "metrics = [dice_coef, iou]\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd017c569aa8db2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=MODEL_PATH, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=4),\n",
    "    CSVLogger(filename=CSV_PATH, append=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=False)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167cd6c7c3e0e1c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=EPOCHS, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa6aaadce0dbf8ce",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
