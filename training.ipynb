{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.160606Z",
     "start_time": "2025-03-03T22:20:58.610213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, functional\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import LRScheduler, StepLR\n",
    "from torch import Tensor\n",
    "\n",
    "from data_loading.dataset import generate_dataloaders\n",
    "from unet import UNet"
   ],
   "id": "4611d6b3ec84f4e5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "2e13d466085162f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.168684Z",
     "start_time": "2025-03-03T22:21:04.164642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 50\n",
    "LR = .001\n",
    "WEIGHT_DECAY = .0001\n",
    "STEP_SIZE = 30"
   ],
   "id": "2347a2c6a1afacde",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generating Dataloaders for feeding the NN",
   "id": "7fd81f0f33a8bca6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.713786Z",
     "start_time": "2025-03-03T22:21:04.315038Z"
    }
   },
   "cell_type": "code",
   "source": "dataloaders = generate_dataloaders(batch_size=BATCH_SIZE, validation_split=0.20)",
   "id": "adc2e15d2eaeceeb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Definition",
   "id": "1bb504381d2c47f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.909709Z",
     "start_time": "2025-03-03T22:21:04.722039Z"
    }
   },
   "cell_type": "code",
   "source": "model = UNet(n_classes=N_CLASSES)",
   "id": "1d52015351514623",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss Functions",
   "id": "c253def3038910a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.925312Z",
     "start_time": "2025-03-03T22:21:04.918287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_loss(prediction: Tensor, ground_truth: Tensor, losses: dict, bce_weight: float = 0.5) -> Tensor:\n",
    "    bce = functional.binary_cross_entropy_with_logits(prediction, ground_truth)\n",
    "    dice = dice_loss(prediction, ground_truth)\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    losses[\"bce\"] += bce.data.cpu().numpy() * ground_truth.size(0)\n",
    "    losses[\"dice\"] += dice.data.cpu().numpy() * ground_truth.size(0)\n",
    "    losses[\"loss\"] += loss.data.cpu().numpy() * ground_truth.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_loss(prediction: Tensor, ground_truth: Tensor, smooth: float = 1e-6) -> Tensor:\n",
    "    prediction = prediction.sigmoid()\n",
    "\n",
    "    prediction = prediction.view(prediction.shape[0], prediction.shape[1], -1)\n",
    "    ground_truth = ground_truth.view(ground_truth.shape[0], ground_truth.shape[1], -1)\n",
    "\n",
    "    intersection = torch.sum(prediction * ground_truth, dim=2)\n",
    "    union = torch.sum(prediction, dim=2) + torch.sum(ground_truth, dim=2)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return 1 - dice.mean()\n"
   ],
   "id": "7eaedd7fb8f42056",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Log Functions",
   "id": "6dabcb63b93ad7aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.942059Z",
     "start_time": "2025-03-03T22:21:04.934016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_metric_to_console(metric_name: str, train_metric: dict, valid_metric: dict) -> None:\n",
    "    \"\"\"\n",
    "    Formats and prints training and validation metric values to console.\n",
    "    Expected metric dict:\n",
    "        {\n",
    "        \"metric1\": metric_name1_value,\n",
    "        \"metric2\": metric_value2,\n",
    "        \"metric3\": metric_value3,\n",
    "        ... }\n",
    "    \"\"\"\n",
    "    print(f\"{metric_name.upper()}:\")\n",
    "    metric_dict = {\"train\": train_metric, \"valid\": valid_metric}\n",
    "    for phase, metric in metric_dict.items():\n",
    "        output = \" \".join(f\"{k}: {v:.5f}\" for k, v in metric.items())\n",
    "        print(f\"\\t({phase}) {output}\")\n",
    "\n",
    "\n",
    "def print_metric_to_tb(writer: SummaryWriter, train_metric: dict, valid_metric: dict, epoch: int) -> None:\n",
    "    \"\"\"\n",
    "    Prints training and validation metric values to Tensorboard.\n",
    "    Expected metric dict:\n",
    "        {\n",
    "        \"metric1\": metric_name1_value,\n",
    "        \"metric2\": metric_value2,\n",
    "        \"metric3\": metric_value3,\n",
    "        ... }\n",
    "    \"\"\"\n",
    "    for key in train_metric.keys():\n",
    "        scalar_dict = {\n",
    "            \"train\": train_metric[key],\n",
    "            \"valid\": valid_metric[key]\n",
    "        }\n",
    "        writer.add_scalars(main_tag=key, tag_scalar_dict=scalar_dict, global_step=epoch)\n",
    "\n",
    "\n",
    "WRITER = SummaryWriter(\"logs/losses\")"
   ],
   "id": "9e0ade43f9ee904d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop",
   "id": "ef9729826591240"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:04.960434Z",
     "start_time": "2025-03-03T22:21:04.950079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_run_name(\n",
    "        model_name: str,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        lr: float,\n",
    "        step_size: int,\n",
    "        weight_decay: float\n",
    ") -> str:\n",
    "    timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return f\"{model_name}_EP{epochs}_BS{batch_size}_LR{lr}_Step{step_size}_WD{weight_decay}_{timestamp}\"\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: Module,\n",
    "        dataloaders: dict,\n",
    "        n_epochs: int,\n",
    "        optimizer: Optimizer,\n",
    "        scheduler: LRScheduler,\n",
    "        device: torch.device = torch.device(\"cpu\")\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{n_epochs}\\n{'=' * 30}\")\n",
    "        print(f\"LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            losses = {\"bce\": 0.0, \"dice\": 0.0, \"loss\": 0.0}\n",
    "            total_loss = 0.0\n",
    "            epoch_samples = 0\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                for batch_X, batch_y in dataloaders[phase]:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    predictions = model(batch_X)\n",
    "                    loss = calculate_loss(prediction=predictions, ground_truth=batch_y, losses=losses)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                    epoch_samples += batch_y.size(0)\n",
    "\n",
    "            avg_losses = {loss_name: value / epoch_samples for loss_name, value in losses.items()}\n",
    "\n",
    "            if phase == \"train\":\n",
    "                train_losses = avg_losses  # save the training loss\n",
    "            else:\n",
    "                print_metric_to_console(metric_name=\"LOSS\", train_metric=train_losses, valid_metric=avg_losses)\n",
    "                print_metric_to_tb(writer=WRITER, train_metric=train_losses, valid_metric=avg_losses, epoch=epoch)\n",
    "\n",
    "                epoch_loss = total_loss / len(dataloaders[phase])\n",
    "                if epoch_loss < best_loss:\n",
    "                    print(\"Saving best model...\")\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        finish_time = round(time.time() - start_time)\n",
    "        print(f\"TIME: {finish_time // 60}min {finish_time % 60}s\")\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best validation loss: {best_loss:.5f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    run_name = generate_run_name(model_name=\"UNet\",\n",
    "                                 weight_decay=WEIGHT_DECAY,\n",
    "                                 lr=LR,\n",
    "                                 step_size=STEP_SIZE,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 epochs=N_EPOCHS\n",
    "                                 )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./models/{run_name}.pth\")\n"
   ],
   "id": "55e32fd2653dcbb0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:21:08.544763Z",
     "start_time": "2025-03-03T22:21:04.969332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/losses"
   ],
   "id": "c72dfdf6b99848a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-34cf5d011d81777\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-34cf5d011d81777\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Optimizer, LR Scheduler and Start Training",
   "id": "a5f023d7aff74d0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T22:27:31.969782Z",
     "start_time": "2025-03-03T22:21:08.551796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = StepLR(optimizer=optimizer, step_size=STEP_SIZE, gamma=0.1)\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    device=device\n",
    ")"
   ],
   "id": "86f4144831c7a757",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "==============================\n",
      "LR: 0.001\n",
      "LOSS:\n",
      "\t(train) bce: 0.36123 dice: 0.94560 loss: 0.65342\n",
      "\t(valid) bce: 0.29536 dice: 0.94677 loss: 0.62107\n",
      "Saving best model...\n",
      "TIME: 4min 17s\n",
      "\n",
      "Epoch 2/50\n",
      "==============================\n",
      "LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
