{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, functional\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import LRScheduler, StepLR\n",
    "from torch import Tensor\n",
    "\n",
    "from data_loading.dataset import generate_dataloaders\n",
    "from metrics.iou import calculate_iou, CHAOSIoUTracker\n",
    "from unet import UNet"
   ],
   "id": "4611d6b3ec84f4e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "2e13d466085162f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N_CLASSES = 4\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 50\n",
    "LR = .001\n",
    "WEIGHT_DECAY = .0001\n",
    "STEP_SIZE = 30"
   ],
   "id": "2347a2c6a1afacde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generating Dataloaders for feeding the NN",
   "id": "7fd81f0f33a8bca6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataloaders = generate_dataloaders(batch_size=BATCH_SIZE, validation_split=0.20)",
   "id": "adc2e15d2eaeceeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Definition",
   "id": "1bb504381d2c47f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = UNet(n_classes=N_CLASSES)",
   "id": "1d52015351514623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss Functions",
   "id": "c253def3038910a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_loss(prediction: Tensor, ground_truth: Tensor, losses: dict, bce_weight: float = 0.5) -> Tensor:\n",
    "    bce = functional.binary_cross_entropy_with_logits(prediction, ground_truth)\n",
    "    dice = dice_loss(prediction, ground_truth)\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    losses[\"bce\"] += bce.data.cpu().numpy() * ground_truth.size(0)\n",
    "    losses[\"dice\"] += dice.data.cpu().numpy() * ground_truth.size(0)\n",
    "    losses[\"loss\"] += loss.data.cpu().numpy() * ground_truth.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_loss(prediction: Tensor, ground_truth: Tensor, smooth: float = 1e-6) -> Tensor:\n",
    "    prediction = prediction.sigmoid()\n",
    "\n",
    "    prediction = prediction.view(prediction.shape[0], prediction.shape[1], -1)\n",
    "    ground_truth = ground_truth.view(ground_truth.shape[0], ground_truth.shape[1], -1)\n",
    "\n",
    "    intersection = torch.sum(prediction * ground_truth, dim=2)\n",
    "    union = torch.sum(prediction, dim=2) + torch.sum(ground_truth, dim=2)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return 1 - dice.mean()\n"
   ],
   "id": "7eaedd7fb8f42056",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Log Functions",
   "id": "6dabcb63b93ad7aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_metric_to_console(name: str, train_metric: dict, valid_metric: dict) -> None:\n",
    "    \"\"\"\n",
    "    Formats and prints training and validation metric values to console.\n",
    "    Expected metric dict:\n",
    "        {\n",
    "        \"metric1\": metric_name1_value,\n",
    "        \"metric2\": metric_value2,\n",
    "        \"metric3\": metric_value3,\n",
    "        ... }\n",
    "    \"\"\"\n",
    "    print(f\"{name.upper()}:\")\n",
    "    metric_dict = {\"train\": train_metric, \"valid\": valid_metric}\n",
    "    for phase, metric in metric_dict.items():\n",
    "        output = \" \".join(f\"{cls}: {score:.5f}\" for cls, score in metric.items())\n",
    "        print(f\"\\t({phase}) {output}\")\n",
    "\n",
    "\n",
    "def print_metric_to_tb(writer: SummaryWriter, train_metric: dict, valid_metric: dict, epoch: int) -> None:\n",
    "    \"\"\"\n",
    "    Prints training and validation metric values to Tensorboard.\n",
    "    Expected metric dict:\n",
    "        {\n",
    "        \"metric1\": metric_name1_value,\n",
    "        \"metric2\": metric_value2,\n",
    "        \"metric3\": metric_value3,\n",
    "        ... }\n",
    "    \"\"\"\n",
    "    for cls in train_metric.keys():\n",
    "        scalar_dict = {\n",
    "            \"train\": train_metric[cls],\n",
    "            \"valid\": valid_metric[cls]\n",
    "        }\n",
    "        writer.add_scalars(main_tag=cls, tag_scalar_dict=scalar_dict, global_step=epoch)\n",
    "\n",
    "\n",
    "WRITER_LOSS = SummaryWriter(\"logs/loss\")\n",
    "WRITER_ACCURACY = SummaryWriter(\"logs/accuracy\")"
   ],
   "id": "9e0ade43f9ee904d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop",
   "id": "ef9729826591240"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_run_name(\n",
    "        model_name: str,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        lr: float,\n",
    "        step_size: int,\n",
    "        weight_decay: float\n",
    ") -> str:\n",
    "    timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return f\"{model_name}_EP{epochs}_BS{batch_size}_LR{lr}_Step{step_size}_WD{weight_decay}_{timestamp}\"\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: Module,\n",
    "        dataloaders: dict,\n",
    "        n_epochs: int,\n",
    "        optimizer: Optimizer,\n",
    "        scheduler: LRScheduler,\n",
    "        device: torch.device = torch.device(\"cpu\")\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{n_epochs}\\n{'=' * 30}\")\n",
    "        print(f\"LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            losses = {\"bce\": 0.0, \"dice\": 0.0, \"loss\": 0.0}\n",
    "            total_loss = 0.0\n",
    "            epoch_samples = 0\n",
    "            accuracy_tracker = CHAOSIoUTracker()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                for images, masks in dataloaders[phase]:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    prediction = model(images)\n",
    "\n",
    "                    loss = calculate_loss(prediction=prediction, ground_truth=masks, losses=losses)\n",
    "\n",
    "                    iou_score = calculate_iou(prediction=prediction, ground_truth=masks)\n",
    "                    accuracy_tracker.update(batch_iou=iou_score, batch_size=masks.size(0))\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                    epoch_samples += masks.size(0)\n",
    "\n",
    "            avg_loss = {name: value / epoch_samples for name, value in losses.items()}\n",
    "            avg_accuracy = accuracy_tracker.get_results()\n",
    "\n",
    "            if phase == \"train\":\n",
    "                train_loss = avg_loss  # save the training loss\n",
    "                train_accuracy = avg_accuracy  # save the training accuracy\n",
    "            else:\n",
    "                # print loss\n",
    "                print_metric_to_console(name=\"LOSS\", train_metric=train_loss, valid_metric=avg_loss)\n",
    "                print_metric_to_tb(writer=WRITER_LOSS, train_metric=train_loss, valid_metric=avg_loss, epoch=epoch)\n",
    "\n",
    "                # print accuracy\n",
    "                print_metric_to_console(\n",
    "                    name=\"ACCURACY(IoU)\",\n",
    "                    train_metric=train_accuracy,\n",
    "                    valid_metric=avg_accuracy\n",
    "                )\n",
    "                print_metric_to_tb(\n",
    "                    writer=WRITER_ACCURACY,\n",
    "                    train_metric=train_accuracy,\n",
    "                    valid_metric=avg_accuracy,\n",
    "                    epoch=epoch\n",
    "                )\n",
    "\n",
    "                epoch_loss = total_loss / len(dataloaders[phase])\n",
    "                if epoch_loss < best_loss:\n",
    "                    print(\"Saving best model...\")\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        finish_time = round(time.time() - start_time)\n",
    "        print(f\"TIME: {finish_time // 60}min {finish_time % 60}s\")\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best validation loss: {best_loss:.5f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    run_name = generate_run_name(model_name=\"UNet\",\n",
    "                                 weight_decay=WEIGHT_DECAY,\n",
    "                                 lr=LR,\n",
    "                                 step_size=STEP_SIZE,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 epochs=N_EPOCHS\n",
    "                                 )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./models/{run_name}.pth\")\n"
   ],
   "id": "55e32fd2653dcbb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/losses"
   ],
   "id": "c72dfdf6b99848a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%tensorboard --logdir logs/accuracies",
   "id": "b77f89fec446c660"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Optimizer, LR Scheduler and Start Training",
   "id": "a5f023d7aff74d0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = StepLR(optimizer=optimizer, step_size=STEP_SIZE, gamma=0.1)\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    device=device\n",
    ")"
   ],
   "id": "86f4144831c7a757",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS:\n",
      "\t(train) bce: 0.07829 dice: 0.83865 loss: 0.45847\n",
      "\t(valid) bce: 0.11657 dice: 0.82053 loss: 0.46855\n",
      "ACCURACY(IOU):\n",
      "\t(train) liver: 0.43357 r_kidney: 0.32086 l_kidney: 0.34772 spleen: 0.32575\n",
      "\t(valid) liver: 0.39052 r_kidney: 0.16710 l_kidney: 0.20785 spleen: 0.18373\n",
      "Saving best model...\n",
      "TIME: 4min 30s\n",
      "\n",
      "Epoch 5/50\n",
      "==============================\n",
      "LR: 0.001\n",
      "LOSS:\n",
      "\t(train) bce: 0.05765 dice: 0.79601 loss: 0.42683\n",
      "\t(valid) bce: 0.06561 dice: 0.78339 loss: 0.42450\n",
      "ACCURACY(IOU):\n",
      "\t(train) liver: 0.48079 r_kidney: 0.41840 l_kidney: 0.33328 spleen: 0.29140\n",
      "\t(valid) liver: 0.37566 r_kidney: 0.23205 l_kidney: 0.33591 spleen: 0.25403\n",
      "Saving best model...\n",
      "TIME: 4min 34s\n",
      "\n",
      "Epoch 6/50\n",
      "==============================\n",
      "LR: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m Adam(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m p: p\u001B[38;5;241m.\u001B[39mrequires_grad, model\u001B[38;5;241m.\u001B[39mparameters()), lr\u001B[38;5;241m=\u001B[39mLR, weight_decay\u001B[38;5;241m=\u001B[39mWEIGHT_DECAY)\n\u001B[0;32m      3\u001B[0m lr_scheduler \u001B[38;5;241m=\u001B[39m StepLR(optimizer\u001B[38;5;241m=\u001B[39moptimizer, step_size\u001B[38;5;241m=\u001B[39mSTEP_SIZE, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 55\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, dataloaders, n_epochs, optimizer, scheduler, device)\u001B[0m\n\u001B[0;32m     52\u001B[0m accuracy_tracker\u001B[38;5;241m.\u001B[39mupdate(batch_iou\u001B[38;5;241m=\u001B[39miou_score, batch_size\u001B[38;5;241m=\u001B[39mbatch_y\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m phase \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 55\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     58\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\Desktop\\Segmentation-of-abdominal-organs-from-medical-images\\venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Segmentation-of-abdominal-organs-from-medical-images\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Segmentation-of-abdominal-organs-from-medical-images\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
